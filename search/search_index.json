{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Infrastructure for Atlassian Data Center products on Kubernetes \u00b6 This project is still under development and is not officially supported. Atlassian DC Apps program provides App vendors in Atlassian ecosystem with tools to setup ready-to-use environment. This project provides a tool to provision infrastructure for Atlassian DC helm chart products. At this stage the scope is providing the infrastructure for Bamboo DC. Prerequisites \u00b6 In order to deploy the infrastructure for Atlassian Data Center products on Kubernetes you need to have the following applications installed on your local machine: AWS CLI helm Terraform See prerequisites for details. Installation \u00b6 Before installing the infrastructure for Atlassian products, please make sure you read the prerequisites section and completed the configuration . After you have done the above steps you can install the Atlassian Data Center infrastructure for selected products. Uninstall the products and infrastructure \u00b6 In installation process, Terraform created all required resources on AWS environment in order to provide the infrastructure to handle Atlassian Data Center products. If you want to uninstall all products and cleanup the infrastructure see cleanup page . Feedback \u00b6 If you find any issue, raise a ticket . If you have general feedback or question regarding the project, use Atlassian Community Kubernetes space . Contributions \u00b6 Contributions are welcome! Find out how to contribute . License \u00b6 Copyright (c) [2021] Atlassian and others. Apache 2.0 licensed, see LICENSE file.","title":"Home"},{"location":"#infrastructure-for-atlassian-data-center-products-on-kubernetes","text":"This project is still under development and is not officially supported. Atlassian DC Apps program provides App vendors in Atlassian ecosystem with tools to setup ready-to-use environment. This project provides a tool to provision infrastructure for Atlassian DC helm chart products. At this stage the scope is providing the infrastructure for Bamboo DC.","title":"Infrastructure for Atlassian Data Center products on Kubernetes"},{"location":"#prerequisites","text":"In order to deploy the infrastructure for Atlassian Data Center products on Kubernetes you need to have the following applications installed on your local machine: AWS CLI helm Terraform See prerequisites for details.","title":"Prerequisites"},{"location":"#installation","text":"Before installing the infrastructure for Atlassian products, please make sure you read the prerequisites section and completed the configuration . After you have done the above steps you can install the Atlassian Data Center infrastructure for selected products.","title":"Installation"},{"location":"#uninstall-the-products-and-infrastructure","text":"In installation process, Terraform created all required resources on AWS environment in order to provide the infrastructure to handle Atlassian Data Center products. If you want to uninstall all products and cleanup the infrastructure see cleanup page .","title":"Uninstall the products and infrastructure"},{"location":"#feedback","text":"If you find any issue, raise a ticket . If you have general feedback or question regarding the project, use Atlassian Community Kubernetes space .","title":"Feedback"},{"location":"#contributions","text":"Contributions are welcome! Find out how to contribute .","title":"Contributions"},{"location":"#license","text":"Copyright (c) [2021] Atlassian and others. Apache 2.0 licensed, see LICENSE file.","title":"License"},{"location":"development/HOW_ADD_PRODUCT/","text":"How to add products \u00b6","title":"How to add products"},{"location":"development/HOW_ADD_PRODUCT/#how-to-add-products","text":"","title":"How to add products"},{"location":"development/HOW_TO_START/","text":"How to start development \u00b6 Here's how to get started with contributing to the Data Center Terraform project. Requirements \u00b6 Make sure that your development environment is configured with the following tools: Terraform Helm v3.3 or later AWS CLI Terraform \u00b6 This project uses Terraform to create and manage the Atlassian Data Center infrastructure on AWS for use with supported Data Center products. Check if Terraform is already installed by running the following command: terraform version If Terraform is not installed, install it by following the official instructions . Helm \u00b6 Make sure that Helm v3.3 or later is installed on your machine. Check if Helm v3.3 or later is already installed by running the following command: helm version --short If Helm is not installed or you're running a version lower than 3.3, install Helm by following the official instructions . AWS CLI \u00b6 We recommend using AWS CLI version 2. Check if AWS CLI version 2 is already installed by running the following command: aws --version If the AWS CLI is not installed or you're running version 1, install AWS CLI version 2 by following the official instructions . Clone the project repository \u00b6 Clone the Data Center Terraform repository locally: git clone git@github.com:atlassian-labs/data-center-terraform.git && cd data-center-terraform GitHub pre-commit hook \u00b6 Configure pre-commit and TFLint to maintain good quality of the committed Terraform code. Install pre-commit . For example: brew install pre-commit In a terminal, change the directory to the repository root and run pre-commit install . Install TFLint . For example: brew install tflint Add the following content to .tflint.hcl : plugin \"aws\" { enabled = true version = \"0.5.0\" source = \"github.com/terraform-linters/tflint-ruleset-aws\" } Initialize TFLint: tflint --init","title":"How to start development"},{"location":"development/HOW_TO_START/#how-to-start-development","text":"Here's how to get started with contributing to the Data Center Terraform project.","title":"How to start development"},{"location":"development/HOW_TO_START/#requirements","text":"Make sure that your development environment is configured with the following tools: Terraform Helm v3.3 or later AWS CLI","title":"Requirements"},{"location":"development/HOW_TO_START/#terraform","text":"This project uses Terraform to create and manage the Atlassian Data Center infrastructure on AWS for use with supported Data Center products. Check if Terraform is already installed by running the following command: terraform version If Terraform is not installed, install it by following the official instructions .","title":"Terraform"},{"location":"development/HOW_TO_START/#helm","text":"Make sure that Helm v3.3 or later is installed on your machine. Check if Helm v3.3 or later is already installed by running the following command: helm version --short If Helm is not installed or you're running a version lower than 3.3, install Helm by following the official instructions .","title":"Helm"},{"location":"development/HOW_TO_START/#aws-cli","text":"We recommend using AWS CLI version 2. Check if AWS CLI version 2 is already installed by running the following command: aws --version If the AWS CLI is not installed or you're running version 1, install AWS CLI version 2 by following the official instructions .","title":"AWS CLI"},{"location":"development/HOW_TO_START/#clone-the-project-repository","text":"Clone the Data Center Terraform repository locally: git clone git@github.com:atlassian-labs/data-center-terraform.git && cd data-center-terraform","title":"Clone the project repository"},{"location":"development/HOW_TO_START/#github-pre-commit-hook","text":"Configure pre-commit and TFLint to maintain good quality of the committed Terraform code. Install pre-commit . For example: brew install pre-commit In a terminal, change the directory to the repository root and run pre-commit install . Install TFLint . For example: brew install tflint Add the following content to .tflint.hcl : plugin \"aws\" { enabled = true version = \"0.5.0\" source = \"github.com/terraform-linters/tflint-ruleset-aws\" } Initialize TFLint: tflint --init","title":"GitHub pre-commit hook"},{"location":"development/HOW_TO_TEST/","text":"Testing \u00b6 Structure \u00b6 You can find the tests in the unittest and e2etest subdirectories under /test . unittest \u00b6 The unittest subdirectory includes module-level terraform plan validation tests. It is required to implement the unit tests for each module. Make sure each test case covers default, customised and invalid conditions. e2etest \u00b6 The e2etest subdirectory contains the end-to-end infrastructure and product tests. The tests cover the entire deployment process, including the provisioning of resources into a cloud provider. Each product will have one test function that covers all the states. The test function starts with generating configurations for the terratest , helm , kubectl commands. You can modify the configuration variables in the GenerateConfigForProductE2eTest() function. The provisioning process is as follows: Create AWS resources using Terraform. Create an EKS namespace (product name by default). Clone the Atlassian Helm chart repository and install the specified product using Helm. Once the cluster and product are initialized, assert functions will validate Terraform outputs. The bamboo_test.go file will only test resource creation and validation To test the destruction, run cleanup_test.go . Requirements \u00b6 The repo uses Terratest to run the tests. Make sure that your testing environment is correctly configured: Installing Terraform \u00b6 Check if Terraform is already installed by running the following command: terraform version If Terraform is not installed, install it by following the official instructions . Installing Go \u00b6 Check if Go is already installed by running the following command: go version If Go is not installed, install it by following the official instructions . Installing AWS CLI \u00b6 We recommend using AWS CLI version 2. Check if AWS CLI version 2 is already installed by running the following command: aws --version If the AWS CLI is not installed or you're running version 1, install AWS CLI version 2 by following the official instructions . Setting up AWS security credentials \u00b6 Set up a user with an administrator IAM role. See Configuration basics \u2014 AWS Command Line Interface . Set credentials to connect to cloud provider. The project looks for ~/.aws . For more details refer to AWS cli-configure-quickstart . Running unit tests \u00b6 To run unit tests, use the following commands: cd test && go get -v -t -d ./... && go mod tidy go test ./unittest/... -v You can use regex keywords to run specific groups of test cases For example, you can run only VPC module-related tests with go test./unittest/... -v -run TestVpc . Running end-to-end tests \u00b6 End-to-end tests take approx. 40\u201360 min. to complete To run end-to-end tests, use the following commands: cd test && mkdir ./e2etest/artifacts go get -v -t -d ./... && go mod tidy go test ./e2etest -v -timeout 40m -run Bamboo | tee ./e2etest/artifacts/e2e-test.log To clean up tests, run: go test ./e2etest -v -timeout 40m -run Cleanup | tee ./e2etest/artifacts/e2e-test-cleanup.log Reusing the end-to-end test environment \u00b6 When you run end-to-end test for the first time, the test function will create an environment configuration file in the /test/e2etest/artifacts directory (the default file name is e2e_test_env_config.json ). You can use this file to reuse the existing Terraform environment directory created by Terratest. You can use the -config flag to specify the configuration file name on the second run and the function will load the configuration and reuse the existing environment. For example: go test ./e2etest -v -timeout 40m -run Bamboo -config = e2e_test_env_config.json | tee ./e2etest/artifacts/e2e-test.log You can do the same to clean up tests: go test ./e2etest -v -timeout 40m -run Cleanup -config = e2e_test_env_config.json | tee ./e2etest/artifacts/e2e-test-cleanup.log Avoid accidentally overwriting the test environment configuration If the -config flag is missing, the second test will create a new test environment and overwrite the e2e_test_env_config.json file if it exists. Rename the e2e_test_env_config.json file to avoid overwriting it. GitHub Actions \u00b6 Unit and end-to-end tests run in GitHub Actions. You can find the configuration files at .github/workflows","title":"Testing"},{"location":"development/HOW_TO_TEST/#testing","text":"","title":"Testing"},{"location":"development/HOW_TO_TEST/#structure","text":"You can find the tests in the unittest and e2etest subdirectories under /test .","title":"Structure"},{"location":"development/HOW_TO_TEST/#unittest","text":"The unittest subdirectory includes module-level terraform plan validation tests. It is required to implement the unit tests for each module. Make sure each test case covers default, customised and invalid conditions.","title":"unittest"},{"location":"development/HOW_TO_TEST/#e2etest","text":"The e2etest subdirectory contains the end-to-end infrastructure and product tests. The tests cover the entire deployment process, including the provisioning of resources into a cloud provider. Each product will have one test function that covers all the states. The test function starts with generating configurations for the terratest , helm , kubectl commands. You can modify the configuration variables in the GenerateConfigForProductE2eTest() function. The provisioning process is as follows: Create AWS resources using Terraform. Create an EKS namespace (product name by default). Clone the Atlassian Helm chart repository and install the specified product using Helm. Once the cluster and product are initialized, assert functions will validate Terraform outputs. The bamboo_test.go file will only test resource creation and validation To test the destruction, run cleanup_test.go .","title":"e2etest"},{"location":"development/HOW_TO_TEST/#requirements","text":"The repo uses Terratest to run the tests. Make sure that your testing environment is correctly configured:","title":"Requirements"},{"location":"development/HOW_TO_TEST/#installing-terraform","text":"Check if Terraform is already installed by running the following command: terraform version If Terraform is not installed, install it by following the official instructions .","title":"Installing Terraform"},{"location":"development/HOW_TO_TEST/#installing-go","text":"Check if Go is already installed by running the following command: go version If Go is not installed, install it by following the official instructions .","title":"Installing Go"},{"location":"development/HOW_TO_TEST/#installing-aws-cli","text":"We recommend using AWS CLI version 2. Check if AWS CLI version 2 is already installed by running the following command: aws --version If the AWS CLI is not installed or you're running version 1, install AWS CLI version 2 by following the official instructions .","title":"Installing AWS CLI"},{"location":"development/HOW_TO_TEST/#setting-up-aws-security-credentials","text":"Set up a user with an administrator IAM role. See Configuration basics \u2014 AWS Command Line Interface . Set credentials to connect to cloud provider. The project looks for ~/.aws . For more details refer to AWS cli-configure-quickstart .","title":"Setting up AWS security credentials"},{"location":"development/HOW_TO_TEST/#running-unit-tests","text":"To run unit tests, use the following commands: cd test && go get -v -t -d ./... && go mod tidy go test ./unittest/... -v You can use regex keywords to run specific groups of test cases For example, you can run only VPC module-related tests with go test./unittest/... -v -run TestVpc .","title":"Running unit tests"},{"location":"development/HOW_TO_TEST/#running-end-to-end-tests","text":"End-to-end tests take approx. 40\u201360 min. to complete To run end-to-end tests, use the following commands: cd test && mkdir ./e2etest/artifacts go get -v -t -d ./... && go mod tidy go test ./e2etest -v -timeout 40m -run Bamboo | tee ./e2etest/artifacts/e2e-test.log To clean up tests, run: go test ./e2etest -v -timeout 40m -run Cleanup | tee ./e2etest/artifacts/e2e-test-cleanup.log","title":"Running end-to-end tests"},{"location":"development/HOW_TO_TEST/#reusing-the-end-to-end-test-environment","text":"When you run end-to-end test for the first time, the test function will create an environment configuration file in the /test/e2etest/artifacts directory (the default file name is e2e_test_env_config.json ). You can use this file to reuse the existing Terraform environment directory created by Terratest. You can use the -config flag to specify the configuration file name on the second run and the function will load the configuration and reuse the existing environment. For example: go test ./e2etest -v -timeout 40m -run Bamboo -config = e2e_test_env_config.json | tee ./e2etest/artifacts/e2e-test.log You can do the same to clean up tests: go test ./e2etest -v -timeout 40m -run Cleanup -config = e2e_test_env_config.json | tee ./e2etest/artifacts/e2e-test-cleanup.log Avoid accidentally overwriting the test environment configuration If the -config flag is missing, the second test will create a new test environment and overwrite the e2e_test_env_config.json file if it exists. Rename the e2e_test_env_config.json file to avoid overwriting it.","title":"Reusing the end-to-end test environment"},{"location":"development/HOW_TO_TEST/#github-actions","text":"Unit and end-to-end tests run in GitHub Actions. You can find the configuration files at .github/workflows","title":"GitHub Actions"},{"location":"troubleshooting/LIMITATIONS/","text":"Limitations \u00b6 Because the project is still under active development, it comes with certain limitations. Product limitations \u00b6 At this time, Bamboo Data Center is the only product with support for Terraform deployment. We're planning to add support for more Atlassian Data Center products in the future. Infrastructure limitations \u00b6 Cloud provider \u00b6 Amazon Web Services (AWS) is the only supported cloud platform. Database \u00b6 PostgreSQL is the defined database engine for the products and cannot be modified in the configuration. However, users can change the database instance type and storage size . Scaling EKS \u00b6 You cannot change the number of the EKS cluster nodes ( desired_capacity ) and node type ( instance_types ) after provisioning the environment. However, the number of application pods can be scaled up as long as the EKS cluster has enough resources.","title":"Limitations"},{"location":"troubleshooting/LIMITATIONS/#limitations","text":"Because the project is still under active development, it comes with certain limitations.","title":"Limitations"},{"location":"troubleshooting/LIMITATIONS/#product-limitations","text":"At this time, Bamboo Data Center is the only product with support for Terraform deployment. We're planning to add support for more Atlassian Data Center products in the future.","title":"Product limitations"},{"location":"troubleshooting/LIMITATIONS/#infrastructure-limitations","text":"","title":"Infrastructure limitations"},{"location":"troubleshooting/LIMITATIONS/#cloud-provider","text":"Amazon Web Services (AWS) is the only supported cloud platform.","title":"Cloud provider"},{"location":"troubleshooting/LIMITATIONS/#database","text":"PostgreSQL is the defined database engine for the products and cannot be modified in the configuration. However, users can change the database instance type and storage size .","title":"Database"},{"location":"troubleshooting/LIMITATIONS/#scaling-eks","text":"You cannot change the number of the EKS cluster nodes ( desired_capacity ) and node type ( instance_types ) after provisioning the environment. However, the number of application pods can be scaled up as long as the EKS cluster has enough resources.","title":"Scaling EKS"},{"location":"troubleshooting/SUPPORT_BOUNDARIES/","text":"Support boundaries \u00b6 This page describes what is within our scope of support for Terraform Data Center deployments. Because this project is still under active development, it is not officially supported. We are planning to update this page with more information in the coming weeks. Additional information Read our troubleshooting tips . Read about the product and platform limitations .","title":"Support boundaries"},{"location":"troubleshooting/SUPPORT_BOUNDARIES/#support-boundaries","text":"This page describes what is within our scope of support for Terraform Data Center deployments. Because this project is still under active development, it is not officially supported. We are planning to update this page with more information in the coming weeks. Additional information Read our troubleshooting tips . Read about the product and platform limitations .","title":"Support boundaries"},{"location":"troubleshooting/TROUBLESHOOTING/","text":"Troubleshooting tips \u00b6 This guide contains general tips on how to investigate an application deployment that doesn't work correctly. Cleanup Terraform state \u00b6 Terraform stores the lock and current state in terraform-backend.tf . This file is generated by the installation process based on the content of config.tfvars . During the installation, both the installer and Terraform generate some temporary files that are removed after the environment has been uninstalled. If you installed an environment and then changed any mandatory configuration settings such as region or environment_name , then clean up all temporary files generated by Terraform before installing a new environment. To clean up local Terraform files, run the following command: ./pkg/scripts/cleanup.sh -t To clean up locally generated variable files, run the following command: ./pkg/scripts/cleanup.sh -s Tip You can clean up both the local Terraform files and locally generated variable files by using the '-t' and '-s' switches in one command: ./pkg/scripts/cleanup.sh -s -t Info Temporary variable files will be regenerated using the configurating file and overriden during the installation process. Uninstall - Invalid configuration file \u00b6 Symptom If you try to uninstall an environment by using a different configuration file than the one you used to install it or by using a different version of the code, you may encounter some issues during uninstallation. In most cases, Terraform reports that the resource cannot be removed because it's in use. Solution Idenity the resource and delete it manually from the AWS console, and then restart the uninstallation process. Tip Always use the same configuration file in uninstallation that you used to install the environment. Uninstall - Stalled product pod \u00b6 Symptom Uninstall fails to remove the persistent volume. Error: Persistent volume atlassian-dc-bamboo-share-home-pv still exists ( Bound ) Error: context deadline exceeded Error: Persistent volume claim atlassian-dc-bamboo-share-home-pvc still exists with Solution If a bamboo pod termination stalls, it will block pvc and pv deletion. To fix this problem we need to terminate product pod first and run uninstall command again. kubectl delete pod <bamboo-pod> -n bamboo --force To see the stalled Bamboo pod name you can run the following command: kubectl get pods -n bamboo Uninstall: Suspended ASG \u00b6 If for any reason Auto Scaling Group gets suspended, AWS does not allow Terraform to delete the node group. Symptom Uninstall process gets interrupted with the following error: Error: error waiting for EKS Node Group ( atlas-ng-second-test-cluster:appNode ) to delete: unexpected state 'DELETE_FAILED' , wanted target '' . last error: 2 errors occurred: * i-06a4b4afc9e7a76b0: NodeCreationFailure: Instances failed to join the kubernetes cluster * eks-appNode-3ebedddc-2d97-ff10-6c23-4900d1d79599: AutoScalingGroupInvalidConfiguration: Couldn ' t terminate instances in ASG as Terminate process is suspended Solution Delete the reported Auto Scaling Group in AWS console and run uninstall command again. Issues while accessing AWS \u00b6 Symptom The following error is thrown: An error occurred ( ExpiredToken ) when calling the GetCallerIdentity operation: The security token included in the request is expired Solution Terraform cannot deploy resources to AWS if your security token has expired. Renew your token and retry. Issues while acquiring state lock \u00b6 If user interrupts the the installation or uninstallation process, Terraform won't be able to unlock resources. In this case, Terraform is unable to acquire state lock in the next attempt. Symptom The following error is thrown: Acquiring state lock. This may take a few moments... Error: Error acquiring the state lock Error message: ConditionalCheckFailedException: The conditional request failed Lock Info: ID: 26f7b9a8-1bef-0674-669b-1d60800dea4d Path: atlassian-data-center-terraform-state-xxxxxxxxxx/bamboo-xxxxxxxxxx/terraform.tfstate Operation: OperationTypeApply Who: xxxxxxxxxx@C02CK0JYMD6V Version: 1 .0.9 Created: 2021 -11-04 00 :50:34.736134 +0000 UTC Info: Solution Forcibly unlock the state by running the following command: terraform force-unlock <ID> Where ' ' is the value that appears in the error message. Are you still having the lock problem after running terraform force-unlock ? There are two Terraform locks\u2014one for the infrastructure and another for Terraform state. If running the following command from the repository directory does not unlock the resources, change the directory to ./pkg/tfstate and retry the same command.","title":"Troubleshooting tips"},{"location":"troubleshooting/TROUBLESHOOTING/#troubleshooting-tips","text":"This guide contains general tips on how to investigate an application deployment that doesn't work correctly.","title":"Troubleshooting tips"},{"location":"troubleshooting/TROUBLESHOOTING/#cleanup-terraform-state","text":"Terraform stores the lock and current state in terraform-backend.tf . This file is generated by the installation process based on the content of config.tfvars . During the installation, both the installer and Terraform generate some temporary files that are removed after the environment has been uninstalled. If you installed an environment and then changed any mandatory configuration settings such as region or environment_name , then clean up all temporary files generated by Terraform before installing a new environment. To clean up local Terraform files, run the following command: ./pkg/scripts/cleanup.sh -t To clean up locally generated variable files, run the following command: ./pkg/scripts/cleanup.sh -s Tip You can clean up both the local Terraform files and locally generated variable files by using the '-t' and '-s' switches in one command: ./pkg/scripts/cleanup.sh -s -t Info Temporary variable files will be regenerated using the configurating file and overriden during the installation process.","title":"Cleanup Terraform state"},{"location":"troubleshooting/TROUBLESHOOTING/#uninstall-invalid-configuration-file","text":"Symptom If you try to uninstall an environment by using a different configuration file than the one you used to install it or by using a different version of the code, you may encounter some issues during uninstallation. In most cases, Terraform reports that the resource cannot be removed because it's in use. Solution Idenity the resource and delete it manually from the AWS console, and then restart the uninstallation process. Tip Always use the same configuration file in uninstallation that you used to install the environment.","title":"Uninstall - Invalid configuration file"},{"location":"troubleshooting/TROUBLESHOOTING/#uninstall-stalled-product-pod","text":"Symptom Uninstall fails to remove the persistent volume. Error: Persistent volume atlassian-dc-bamboo-share-home-pv still exists ( Bound ) Error: context deadline exceeded Error: Persistent volume claim atlassian-dc-bamboo-share-home-pvc still exists with Solution If a bamboo pod termination stalls, it will block pvc and pv deletion. To fix this problem we need to terminate product pod first and run uninstall command again. kubectl delete pod <bamboo-pod> -n bamboo --force To see the stalled Bamboo pod name you can run the following command: kubectl get pods -n bamboo","title":"Uninstall - Stalled product pod"},{"location":"troubleshooting/TROUBLESHOOTING/#uninstall-suspended-asg","text":"If for any reason Auto Scaling Group gets suspended, AWS does not allow Terraform to delete the node group. Symptom Uninstall process gets interrupted with the following error: Error: error waiting for EKS Node Group ( atlas-ng-second-test-cluster:appNode ) to delete: unexpected state 'DELETE_FAILED' , wanted target '' . last error: 2 errors occurred: * i-06a4b4afc9e7a76b0: NodeCreationFailure: Instances failed to join the kubernetes cluster * eks-appNode-3ebedddc-2d97-ff10-6c23-4900d1d79599: AutoScalingGroupInvalidConfiguration: Couldn ' t terminate instances in ASG as Terminate process is suspended Solution Delete the reported Auto Scaling Group in AWS console and run uninstall command again.","title":"Uninstall: Suspended ASG"},{"location":"troubleshooting/TROUBLESHOOTING/#issues-while-accessing-aws","text":"Symptom The following error is thrown: An error occurred ( ExpiredToken ) when calling the GetCallerIdentity operation: The security token included in the request is expired Solution Terraform cannot deploy resources to AWS if your security token has expired. Renew your token and retry.","title":"Issues while accessing AWS"},{"location":"troubleshooting/TROUBLESHOOTING/#issues-while-acquiring-state-lock","text":"If user interrupts the the installation or uninstallation process, Terraform won't be able to unlock resources. In this case, Terraform is unable to acquire state lock in the next attempt. Symptom The following error is thrown: Acquiring state lock. This may take a few moments... Error: Error acquiring the state lock Error message: ConditionalCheckFailedException: The conditional request failed Lock Info: ID: 26f7b9a8-1bef-0674-669b-1d60800dea4d Path: atlassian-data-center-terraform-state-xxxxxxxxxx/bamboo-xxxxxxxxxx/terraform.tfstate Operation: OperationTypeApply Who: xxxxxxxxxx@C02CK0JYMD6V Version: 1 .0.9 Created: 2021 -11-04 00 :50:34.736134 +0000 UTC Info: Solution Forcibly unlock the state by running the following command: terraform force-unlock <ID> Where ' ' is the value that appears in the error message. Are you still having the lock problem after running terraform force-unlock ? There are two Terraform locks\u2014one for the infrastructure and another for Terraform state. If running the following command from the repository directory does not unlock the resources, change the directory to ./pkg/tfstate and retry the same command.","title":"Issues while acquiring state lock"},{"location":"userguide/CLEANUP/","text":"Uninstallation and cleanup \u00b6 This guide describes how to uninstall all Atlassian Data Center products and remove cloud environments The uninstallation process is destructive The uninstallation process will permanently delete the local volume, shared volume, database, and Terraform state information. Before you begin, make sure that you have an up-to-date backup available in a secure location. If you want to uninstall just one product, don't proceed with the uninstallation process and remove it from the configuration file instead. For more information, see Configuration . The uninstallation script is located in the pkg/scripts project directory. Usage: ./uninstall.sh [ -t ] [ -c <config.tfvars> ] The following options are available: -t - Delete Terraform state files -c <config_file> - Pass a custom configuration file when uninstalling multiple environments Running the uninstallation script with no parameters will use the default configuration file. You can remove environments provisioned with the default configuration file as well as the ones provisioned with a custom configuration file. Removing environments provisioned with the default configuration file \u00b6 If you used the default configuration file ( config.tfvars ) from the root folder of the project, run the following command: ./uninstall.sh Removing environments provisioned with a custom configuration file \u00b6 If you used a custom configuration file to provision the infrastructure, run the following command using the same configuration file: ./uninstall.sh -c <custom-config-file> Removing Terraform state files \u00b6 By default, the script does not remove Terraform state files. If you want to remove Terraform state files, run the uninstallation script with the -t switch: ./uninstall.sh -t [ -c <custom-config-file> ]","title":"Uninstallation and cleanup"},{"location":"userguide/CLEANUP/#uninstallation-and-cleanup","text":"This guide describes how to uninstall all Atlassian Data Center products and remove cloud environments The uninstallation process is destructive The uninstallation process will permanently delete the local volume, shared volume, database, and Terraform state information. Before you begin, make sure that you have an up-to-date backup available in a secure location. If you want to uninstall just one product, don't proceed with the uninstallation process and remove it from the configuration file instead. For more information, see Configuration . The uninstallation script is located in the pkg/scripts project directory. Usage: ./uninstall.sh [ -t ] [ -c <config.tfvars> ] The following options are available: -t - Delete Terraform state files -c <config_file> - Pass a custom configuration file when uninstalling multiple environments Running the uninstallation script with no parameters will use the default configuration file. You can remove environments provisioned with the default configuration file as well as the ones provisioned with a custom configuration file.","title":"Uninstallation and cleanup"},{"location":"userguide/CLEANUP/#removing-environments-provisioned-with-the-default-configuration-file","text":"If you used the default configuration file ( config.tfvars ) from the root folder of the project, run the following command: ./uninstall.sh","title":"Removing environments provisioned with the default configuration file"},{"location":"userguide/CLEANUP/#removing-environments-provisioned-with-a-custom-configuration-file","text":"If you used a custom configuration file to provision the infrastructure, run the following command using the same configuration file: ./uninstall.sh -c <custom-config-file>","title":"Removing environments provisioned with a custom configuration file"},{"location":"userguide/CLEANUP/#removing-terraform-state-files","text":"By default, the script does not remove Terraform state files. If you want to remove Terraform state files, run the uninstallation script with the -t switch: ./uninstall.sh -t [ -c <custom-config-file> ]","title":"Removing Terraform state files"},{"location":"userguide/CONFIGURATION/","text":"Configuration \u00b6 In order to provision the infrastructure and install an Atlassian Data Center product, you need to create a valid Terraform configuration. All configuration data should go to a terraform variable file. The content of the configuration file is divided into two groups: Mandatory configuration Optional configuration Configuration file format. The configuration file is an ASCII text file with the .tfvars extension. The config file must contain all mandatory configuration items with valid values. If any optional items are missing, the default values will be applied. The mandatory configuration items are those you should define once before the first installation. Mandatory values cannot be changed in the entire environment lifecycle. The optional configuration items are not required for installation by default. Optional values may change at any point in the environment lifecycle. Terraform will retain the latest state of the environment and keep track of any configuration changes made later. The following is an example of a valid configuration file: # Mandatory items environment_name = \"my-bamboo-env\" region = \"us-east-2\" # Optional items resource_tags = { Terraform = \"true\" , Organization = \"atlassian\" , product = \"bamboo\" , } instance_types = [ \"m5.xlarge\" ] desired_capacity = 2 domain = \"mydomain.com\" Mandatory configuration \u00b6 Environment name \u00b6 environment_name provides your environment a unique name within a single cloud provider account. This value cannot be altered after the configuration has been applied. The value will be used to form the name of some resources including vpc and Kubernetes cluster . environment_name = \"<YOUR-ENVIRONMENT-NAME>\" Environment names should start with a letter and can contain letters, numbers, and dashes ( - ). The maximum value length is 25 characters. Region \u00b6 region defines the cloud provider region that the environment will be deployed to. The value must be a valid AWS region . region = \"<Region>\" # e.g: \"ap-northeast-2\" Bamboo License \u00b6 bamboo_license takes the license key of Bamboo product. Make sure that there is no new lines or spaces in license key. bamboo_license = \"<license key>\" Sensitive data bamboo_license is marked as sensitive, storing in a plain-text config.tfvars file is not recommended. Please refer to Sensitive Data section. Bamboo System Admin Credentials \u00b6 Four values are required to configure Bamboo system admin credentials. bamboo_admin_username = \"<username>\" bamboo_admin_password = \"<password>\" bamboo_admin_display_name = \"<display name>\" bamboo_admin_email_address = \"<email address>\" Sensitive data bamboo_admin_password is marked as sensitive, storing in a plain-text config.tfvars file is not recommended. Please refer to Sensitive Data section. Restoring from existing dataset If the dataset_url variable is provided, the Bamboo System Admin Credentials properties are ignored. You will need to use user credentials from the dataset to log into the instance. Optional configuration \u00b6 Restoring from backup \u00b6 To restore data from an existing Bamboo backup , you can set the dataset_url variable to a publicly accessible URL where the dataset can be downloaded. dataset_url = \"https://bamboo-test-datasets.s3.amazonaws.com/dcapt-bamboo-no-agents.zip\" This dataset is downloaded to the shared home and then imported by the Bamboo instance. To log in to the instance, you will need to use any credentials from the dataset. Provisioning time Restoring from the dataset will increase the time it takes to create the environment. Resource tags \u00b6 resource_tags are custom metadata for all resources in the environment. You can provide multiple tags as a list. Tag names must be unique. resource_tags = { <tag-name- 0 > = \"<tag-value>\" , <tag-name- 1 > = \"<tag-value>\" , ... <tag-name-n> = \"<tag-value>\" , } Using Terraform CLI to apply tags is not recommended and may lead to missing tags in some resources. To apply tags to all resources, follow the installation guide . Cluster instance type \u00b6 instance_types provides the instance types for the Kubernetes cluster node group. instance_types = [ \"instance-type\"] # e.g: [\"m5.2xlarge\" ] If an instance_types value is not defined in the configuration file, the default value of m5.4xlarge is used. The instance type must be a valid AWS instance type . You cannot change this value after the infrastructure is provisioned. Cluster size \u00b6 desired_capacity provides the desired number of nodes that the node group should launch with initially. The default value for the number of nodes in Kubernetes node groups is 2 . Minimum is 1 and maximum is 10 . This value cannot be changed after the infrastructure is provisioned. desired_capacity = < number -of-nodes> # between 1 and 10 Domain name \u00b6 We recommend using a domain name to access the application via HTTPS. You will be required to secure a domain name and supply the configuration to the config file. When the domain is provided, Terraform will create a Route53 hosted zone based on the environment name. domain = \"<domain-name>\" # for example: \"mydomain.com\" A fully qualified domain name uses the following format: <product>.<environment-name>.<domain-name> . For example bamboo.staging.mydomain.com . Removing domain from deployment Removing the domain name to revert to an insecure connection is not possible after the environment has been deployed (see below). Ingress controller If a domain name is defined, Terraform will create a nginx-ingress controller in the EKS cluster that will provide access to the application via the domain name. Terraform will also create an ACM certificate to provide secure connections over HTTPS. Provisioning without a domain name \u00b6 You can provision the infrastructure without a domain name by commenting out the domain variable in the .tfvars file. In that case, the application will run unsecured on an elastic load balancer domain: http://<load-balancer-id>.<region>.elb.amazonaws.com . The final URL is printed out as part of the outputs after the infrastructure has been provisioned. Database Instance Class \u00b6 db_instance_class sets the DB instance type that allocates the computational, network, and memory capacity required by the planned workload of the DB instance. For more information about available instance classes, see DB instance classes \u2014 Amazon Relational Database Service . db_instance_class = \"<instance.class>\" # e.g. \"db.t3.micro\" Database allocated storage \u00b6 db_allocated_storage sets the allocated storage for the database instance in GiB. db_allocated_storage = 100 The allowed value range of allocated storage may vary based on instance class You may want to adjust these values according to your needs. For more information, see Amazon RDS DB instance storage \u2014 Amazon Relational Database Service . Database IOPS \u00b6 db_iops sets the requested number of I/O operations per second that the DB instance can support. db_iops = 1000 The allowed value range of IOPS may vary based on instance class You may want to adjust these values according to your needs. For more information, see Amazon RDS DB instance storage \u2014 Amazon Relational Database Service . Number of Bamboo agents \u00b6 number_of_bamboo_agents sets the number of remote agents to be launched. To disable agents, set this value to 0 . number_of_bamboo_agents = 50 The value should not be greater than the number of allowed agents in your license. Any agents beyond the allowed number won't be able to join the cluster. Sensitive Data \u00b6 Sensitive input data will eventually be stored as secrets within Kubernetes cluster . We use config.tfvars file to pass configuration values to Terraform stack. The file itself is plain-text on local machine, and will not be stored in remote backend where all the Terraform state files will be stored encrypted. More info regarding sensitive data in Terraform state can be found here . To avoid storing sensitive data in a plain-text file like config.tfvars , we recommend storing them in environment variables prefixed with TF_VAR_ . Take bamboo_admin_password for example, for Linux-like sytems, run the following command to write bamboo admin password to environment variable: export TF_VAR_bamboo_admin_password = <password> If storing these data as plain-text is not a particular concern for the environment to be deployed, you can also choose to supply the values in config.tfvars file. Uncomment the corresponding line and configure the value there.","title":"Configuration"},{"location":"userguide/CONFIGURATION/#configuration","text":"In order to provision the infrastructure and install an Atlassian Data Center product, you need to create a valid Terraform configuration. All configuration data should go to a terraform variable file. The content of the configuration file is divided into two groups: Mandatory configuration Optional configuration Configuration file format. The configuration file is an ASCII text file with the .tfvars extension. The config file must contain all mandatory configuration items with valid values. If any optional items are missing, the default values will be applied. The mandatory configuration items are those you should define once before the first installation. Mandatory values cannot be changed in the entire environment lifecycle. The optional configuration items are not required for installation by default. Optional values may change at any point in the environment lifecycle. Terraform will retain the latest state of the environment and keep track of any configuration changes made later. The following is an example of a valid configuration file: # Mandatory items environment_name = \"my-bamboo-env\" region = \"us-east-2\" # Optional items resource_tags = { Terraform = \"true\" , Organization = \"atlassian\" , product = \"bamboo\" , } instance_types = [ \"m5.xlarge\" ] desired_capacity = 2 domain = \"mydomain.com\"","title":"Configuration"},{"location":"userguide/CONFIGURATION/#mandatory-configuration","text":"","title":"Mandatory configuration"},{"location":"userguide/CONFIGURATION/#environment-name","text":"environment_name provides your environment a unique name within a single cloud provider account. This value cannot be altered after the configuration has been applied. The value will be used to form the name of some resources including vpc and Kubernetes cluster . environment_name = \"<YOUR-ENVIRONMENT-NAME>\" Environment names should start with a letter and can contain letters, numbers, and dashes ( - ). The maximum value length is 25 characters.","title":"Environment name"},{"location":"userguide/CONFIGURATION/#region","text":"region defines the cloud provider region that the environment will be deployed to. The value must be a valid AWS region . region = \"<Region>\" # e.g: \"ap-northeast-2\"","title":"Region"},{"location":"userguide/CONFIGURATION/#bamboo-license","text":"bamboo_license takes the license key of Bamboo product. Make sure that there is no new lines or spaces in license key. bamboo_license = \"<license key>\" Sensitive data bamboo_license is marked as sensitive, storing in a plain-text config.tfvars file is not recommended. Please refer to Sensitive Data section.","title":"Bamboo License"},{"location":"userguide/CONFIGURATION/#bamboo-system-admin-credentials","text":"Four values are required to configure Bamboo system admin credentials. bamboo_admin_username = \"<username>\" bamboo_admin_password = \"<password>\" bamboo_admin_display_name = \"<display name>\" bamboo_admin_email_address = \"<email address>\" Sensitive data bamboo_admin_password is marked as sensitive, storing in a plain-text config.tfvars file is not recommended. Please refer to Sensitive Data section. Restoring from existing dataset If the dataset_url variable is provided, the Bamboo System Admin Credentials properties are ignored. You will need to use user credentials from the dataset to log into the instance.","title":"Bamboo System Admin Credentials"},{"location":"userguide/CONFIGURATION/#optional-configuration","text":"","title":"Optional configuration"},{"location":"userguide/CONFIGURATION/#restoring-from-backup","text":"To restore data from an existing Bamboo backup , you can set the dataset_url variable to a publicly accessible URL where the dataset can be downloaded. dataset_url = \"https://bamboo-test-datasets.s3.amazonaws.com/dcapt-bamboo-no-agents.zip\" This dataset is downloaded to the shared home and then imported by the Bamboo instance. To log in to the instance, you will need to use any credentials from the dataset. Provisioning time Restoring from the dataset will increase the time it takes to create the environment.","title":"Restoring from backup"},{"location":"userguide/CONFIGURATION/#resource-tags","text":"resource_tags are custom metadata for all resources in the environment. You can provide multiple tags as a list. Tag names must be unique. resource_tags = { <tag-name- 0 > = \"<tag-value>\" , <tag-name- 1 > = \"<tag-value>\" , ... <tag-name-n> = \"<tag-value>\" , } Using Terraform CLI to apply tags is not recommended and may lead to missing tags in some resources. To apply tags to all resources, follow the installation guide .","title":"Resource tags"},{"location":"userguide/CONFIGURATION/#cluster-instance-type","text":"instance_types provides the instance types for the Kubernetes cluster node group. instance_types = [ \"instance-type\"] # e.g: [\"m5.2xlarge\" ] If an instance_types value is not defined in the configuration file, the default value of m5.4xlarge is used. The instance type must be a valid AWS instance type . You cannot change this value after the infrastructure is provisioned.","title":"Cluster instance type"},{"location":"userguide/CONFIGURATION/#cluster-size","text":"desired_capacity provides the desired number of nodes that the node group should launch with initially. The default value for the number of nodes in Kubernetes node groups is 2 . Minimum is 1 and maximum is 10 . This value cannot be changed after the infrastructure is provisioned. desired_capacity = < number -of-nodes> # between 1 and 10","title":"Cluster size"},{"location":"userguide/CONFIGURATION/#domain-name","text":"We recommend using a domain name to access the application via HTTPS. You will be required to secure a domain name and supply the configuration to the config file. When the domain is provided, Terraform will create a Route53 hosted zone based on the environment name. domain = \"<domain-name>\" # for example: \"mydomain.com\" A fully qualified domain name uses the following format: <product>.<environment-name>.<domain-name> . For example bamboo.staging.mydomain.com . Removing domain from deployment Removing the domain name to revert to an insecure connection is not possible after the environment has been deployed (see below). Ingress controller If a domain name is defined, Terraform will create a nginx-ingress controller in the EKS cluster that will provide access to the application via the domain name. Terraform will also create an ACM certificate to provide secure connections over HTTPS.","title":"Domain name"},{"location":"userguide/CONFIGURATION/#provisioning-without-a-domain-name","text":"You can provision the infrastructure without a domain name by commenting out the domain variable in the .tfvars file. In that case, the application will run unsecured on an elastic load balancer domain: http://<load-balancer-id>.<region>.elb.amazonaws.com . The final URL is printed out as part of the outputs after the infrastructure has been provisioned.","title":"Provisioning without a domain name"},{"location":"userguide/CONFIGURATION/#database-instance-class","text":"db_instance_class sets the DB instance type that allocates the computational, network, and memory capacity required by the planned workload of the DB instance. For more information about available instance classes, see DB instance classes \u2014 Amazon Relational Database Service . db_instance_class = \"<instance.class>\" # e.g. \"db.t3.micro\"","title":"Database Instance Class"},{"location":"userguide/CONFIGURATION/#database-allocated-storage","text":"db_allocated_storage sets the allocated storage for the database instance in GiB. db_allocated_storage = 100 The allowed value range of allocated storage may vary based on instance class You may want to adjust these values according to your needs. For more information, see Amazon RDS DB instance storage \u2014 Amazon Relational Database Service .","title":"Database allocated storage"},{"location":"userguide/CONFIGURATION/#database-iops","text":"db_iops sets the requested number of I/O operations per second that the DB instance can support. db_iops = 1000 The allowed value range of IOPS may vary based on instance class You may want to adjust these values according to your needs. For more information, see Amazon RDS DB instance storage \u2014 Amazon Relational Database Service .","title":"Database IOPS"},{"location":"userguide/CONFIGURATION/#number-of-bamboo-agents","text":"number_of_bamboo_agents sets the number of remote agents to be launched. To disable agents, set this value to 0 . number_of_bamboo_agents = 50 The value should not be greater than the number of allowed agents in your license. Any agents beyond the allowed number won't be able to join the cluster.","title":"Number of Bamboo agents"},{"location":"userguide/CONFIGURATION/#sensitive-data","text":"Sensitive input data will eventually be stored as secrets within Kubernetes cluster . We use config.tfvars file to pass configuration values to Terraform stack. The file itself is plain-text on local machine, and will not be stored in remote backend where all the Terraform state files will be stored encrypted. More info regarding sensitive data in Terraform state can be found here . To avoid storing sensitive data in a plain-text file like config.tfvars , we recommend storing them in environment variables prefixed with TF_VAR_ . Take bamboo_admin_password for example, for Linux-like sytems, run the following command to write bamboo admin password to environment variable: export TF_VAR_bamboo_admin_password = <password> If storing these data as plain-text is not a particular concern for the environment to be deployed, you can also choose to supply the values in config.tfvars file. Uncomment the corresponding line and configure the value there.","title":"Sensitive Data"},{"location":"userguide/INSTALLATION/","text":"Installation \u00b6 This guide describes how to provision the cloud environment infrastructure and install Atlassian Data Center products in a Kubernetes cluster running on AWS. Supported Atlassian Data Center products Currently, only Bamboo Data Center is supported. We are planning to to add support for more Data Center products in the future. 1. Set up AWS security credentials \u00b6 Set up a user with an administrator IAM role. See Configuration basics \u2014 AWS Command Line Interface . 2. Clone the project repository \u00b6 Clone the Terraform for Atlassian DC Products project repository from GitHub: git clone -b 0 .0.2-beta https://github.com/atlassian-labs/data-center-terraform.git && cd data-center-terraform 3. Configure the infrastructure \u00b6 Configure the infrastructure for the selected product or products by opening the configuration file in a text editor and defining the required values. See Configuration . Where is the configuration file? By default, Terraform uses the config.tfvars file in the project root to configure the infrastructure during the installation or uninstallation processes. Can I use a custom configuration file? You can use a custom configuration file, but it must follow the same format as the default configuration file. You can make a copy of config.tfvars , using it as a template to define your infrastructure configuration. Use the same configuration file for uninstallation and cleanup If you have more than one environment, make sure to manage the configuration file for each environment separately. When cleaning up your environment, use the same configuration file that was used to create it originally. 4. Run the installation script \u00b6 The installation script provisions the environment infrastructure and installs the selected products based on the passed configuration file. The installation is unattended and invokes Terraform to handle the creation and management of the Kubernetes infrastructure. To keep track of the current state of the resources and manage changes, Terraform creates an S3 bucket to store the current state of the environment. A DynamoDB table is created to handle the locking of remote state files during the installation, upgrade, and cleanup stages to prevent the environment from being modified by more than one process at a time. The installation script is located in the root folder of the project. Usage: ./install.sh [ -c <config-file ] [ -h ] The following options are available: -c <config_file> - Pass a custom configuration file when provisioning multiple environments -h - Display help information Running the installation script with no parameters will use the default configuration file to provision the environment. Start the installation using the default configuration file \u00b6 To provision the infrastructure using the default config.tfvars file, run: ./install.sh Start the installation using a custom configuration file \u00b6 If you want to use a custom configuration file to handle more than one environment, run: ./install.sh -c <config_file_path> How to run the product after installation? When the installation process finishes successfully, you can find some detailed information about the infrastructure in the console, including the product URL that you can follow to launch the product in the browser. Where do I find the database username and password? The database master username and password for each product are generated by Terraform and saved in a Kubernetes secret in the product namespace. To access the database username and password, run the following commands: DB_SECRETS=$(kubectl get secret <product-name>-db-cred -n <product-name> -o jsonpath='{.data}') DB_USERNAME=$(echo $DB_SECRETS | jq -r '.username' | base64 --decode) DB_PASSWORD=$(echo $DB_SECRETS | jq -r '.password' | base64 --decode) This saves the decoded username and password to the $DB_USERNAME and $DB_PASSWORD environment variables respectively.","title":"Installation"},{"location":"userguide/INSTALLATION/#installation","text":"This guide describes how to provision the cloud environment infrastructure and install Atlassian Data Center products in a Kubernetes cluster running on AWS. Supported Atlassian Data Center products Currently, only Bamboo Data Center is supported. We are planning to to add support for more Data Center products in the future.","title":"Installation"},{"location":"userguide/INSTALLATION/#1-set-up-aws-security-credentials","text":"Set up a user with an administrator IAM role. See Configuration basics \u2014 AWS Command Line Interface .","title":"1. Set up AWS security credentials"},{"location":"userguide/INSTALLATION/#2-clone-the-project-repository","text":"Clone the Terraform for Atlassian DC Products project repository from GitHub: git clone -b 0 .0.2-beta https://github.com/atlassian-labs/data-center-terraform.git && cd data-center-terraform","title":"2. Clone the project repository"},{"location":"userguide/INSTALLATION/#3-configure-the-infrastructure","text":"Configure the infrastructure for the selected product or products by opening the configuration file in a text editor and defining the required values. See Configuration . Where is the configuration file? By default, Terraform uses the config.tfvars file in the project root to configure the infrastructure during the installation or uninstallation processes. Can I use a custom configuration file? You can use a custom configuration file, but it must follow the same format as the default configuration file. You can make a copy of config.tfvars , using it as a template to define your infrastructure configuration. Use the same configuration file for uninstallation and cleanup If you have more than one environment, make sure to manage the configuration file for each environment separately. When cleaning up your environment, use the same configuration file that was used to create it originally.","title":"3. Configure the infrastructure"},{"location":"userguide/INSTALLATION/#4-run-the-installation-script","text":"The installation script provisions the environment infrastructure and installs the selected products based on the passed configuration file. The installation is unattended and invokes Terraform to handle the creation and management of the Kubernetes infrastructure. To keep track of the current state of the resources and manage changes, Terraform creates an S3 bucket to store the current state of the environment. A DynamoDB table is created to handle the locking of remote state files during the installation, upgrade, and cleanup stages to prevent the environment from being modified by more than one process at a time. The installation script is located in the root folder of the project. Usage: ./install.sh [ -c <config-file ] [ -h ] The following options are available: -c <config_file> - Pass a custom configuration file when provisioning multiple environments -h - Display help information Running the installation script with no parameters will use the default configuration file to provision the environment.","title":"4. Run the installation script"},{"location":"userguide/INSTALLATION/#start-the-installation-using-the-default-configuration-file","text":"To provision the infrastructure using the default config.tfvars file, run: ./install.sh","title":"Start the installation using the default configuration file"},{"location":"userguide/INSTALLATION/#start-the-installation-using-a-custom-configuration-file","text":"If you want to use a custom configuration file to handle more than one environment, run: ./install.sh -c <config_file_path> How to run the product after installation? When the installation process finishes successfully, you can find some detailed information about the infrastructure in the console, including the product URL that you can follow to launch the product in the browser. Where do I find the database username and password? The database master username and password for each product are generated by Terraform and saved in a Kubernetes secret in the product namespace. To access the database username and password, run the following commands: DB_SECRETS=$(kubectl get secret <product-name>-db-cred -n <product-name> -o jsonpath='{.data}') DB_USERNAME=$(echo $DB_SECRETS | jq -r '.username' | base64 --decode) DB_PASSWORD=$(echo $DB_SECRETS | jq -r '.password' | base64 --decode) This saves the decoded username and password to the $DB_USERNAME and $DB_PASSWORD environment variables respectively.","title":"Start the installation using a custom configuration file"},{"location":"userguide/PREREQUISITES/","text":"Prerequisites \u00b6 Before installing the infrastructure for Atlassian Data Center products, make sure that you meet the following requirements and that your local environment is configured with all the necessary tools. Requirements \u00b6 In order to deploy Atlassian\u2019s Data Center infrastructure to Amazon Web Services (AWS), the following are required: An understanding of Kubernetes and Helm concepts. An understanding of Terraform . An AWS account with admin access. Environment setup \u00b6 Before creating the infrastructure, make sure that your development environment is configured with the following tools: Terraform Helm v3.3 or later AWS CLI Kubernetes cluster monitoring tools (optional) Terraform \u00b6 Terraform is an open-source infrastructure as code tool that provides a consistent CLI workflow to create and manage the infrastructure of cloud environments. This project uses Terraform to create and manage the Atlassian Data Center infrastructure on AWS for use with supported Data Center products. Currently, not all Data Center products are supported. At this stage, Bamboo Data Center is the only supported product. Check if Terraform is already installed by running the following command: terraform version If Terraform is not installed, install it by following the official instructions . Helm \u00b6 Atlassian supports Helm Charts for some of its Data Center products , including Bamboo. This project uses Helm charts to package Bamboo Data Center as a turnkey solution for your cloud infrastructure. Before using this project, make sure that Helm v3.3 or later is installed on your machine. Check if Helm v3.3 or later is already installed by running the following command: helm version --short If Helm is not installed or you're running a version lower than 3.3, install Helm by following the official instructions . AWS CLI \u00b6 You need to have the AWS CLI tool installed on your local machine before creating the Kubernetes infrastructure. We recommend using AWS CLI version 2. Check if AWS CLI version 2 is already installed by running the following command: aws --version If the AWS CLI is not installed or you're running version 1, install AWS CLI version 2 by following the official instructions . Kubernetes cluster monitoring tools \u00b6 This step is not mandatory in order to use Terraform for Atlassian Data Center products, but we recommend installing tools such as kubectl to be able monitor and diagnose the resources in the Kubernetes cluster. Other Kubernetes cluster monitoring tools Alternatively, you can use other open-source Kubernetes cluster monitoring monitoring tools, such as Prometheus Grafana , or Weave Scope .","title":"Prerequisites"},{"location":"userguide/PREREQUISITES/#prerequisites","text":"Before installing the infrastructure for Atlassian Data Center products, make sure that you meet the following requirements and that your local environment is configured with all the necessary tools.","title":"Prerequisites"},{"location":"userguide/PREREQUISITES/#requirements","text":"In order to deploy Atlassian\u2019s Data Center infrastructure to Amazon Web Services (AWS), the following are required: An understanding of Kubernetes and Helm concepts. An understanding of Terraform . An AWS account with admin access.","title":"Requirements"},{"location":"userguide/PREREQUISITES/#environment-setup","text":"Before creating the infrastructure, make sure that your development environment is configured with the following tools: Terraform Helm v3.3 or later AWS CLI Kubernetes cluster monitoring tools (optional)","title":"Environment setup"},{"location":"userguide/PREREQUISITES/#terraform","text":"Terraform is an open-source infrastructure as code tool that provides a consistent CLI workflow to create and manage the infrastructure of cloud environments. This project uses Terraform to create and manage the Atlassian Data Center infrastructure on AWS for use with supported Data Center products. Currently, not all Data Center products are supported. At this stage, Bamboo Data Center is the only supported product. Check if Terraform is already installed by running the following command: terraform version If Terraform is not installed, install it by following the official instructions .","title":" Terraform"},{"location":"userguide/PREREQUISITES/#helm","text":"Atlassian supports Helm Charts for some of its Data Center products , including Bamboo. This project uses Helm charts to package Bamboo Data Center as a turnkey solution for your cloud infrastructure. Before using this project, make sure that Helm v3.3 or later is installed on your machine. Check if Helm v3.3 or later is already installed by running the following command: helm version --short If Helm is not installed or you're running a version lower than 3.3, install Helm by following the official instructions .","title":" Helm"},{"location":"userguide/PREREQUISITES/#aws-cli","text":"You need to have the AWS CLI tool installed on your local machine before creating the Kubernetes infrastructure. We recommend using AWS CLI version 2. Check if AWS CLI version 2 is already installed by running the following command: aws --version If the AWS CLI is not installed or you're running version 1, install AWS CLI version 2 by following the official instructions .","title":" AWS CLI"},{"location":"userguide/PREREQUISITES/#kubernetes-cluster-monitoring-tools","text":"This step is not mandatory in order to use Terraform for Atlassian Data Center products, but we recommend installing tools such as kubectl to be able monitor and diagnose the resources in the Kubernetes cluster. Other Kubernetes cluster monitoring tools Alternatively, you can use other open-source Kubernetes cluster monitoring monitoring tools, such as Prometheus Grafana , or Weave Scope .","title":" Kubernetes cluster monitoring tools"},{"location":"userguide/UPGRADE/","text":"Upgrade \u00b6","title":"Upgrade"},{"location":"userguide/UPGRADE/#upgrade","text":"","title":"Upgrade"},{"location":"userguide/VERSIONING/","text":"Versioning \u00b6 Release naming \u00b6 Each product version is semantically versioned . Version names are defined by the following pattern: MAJOR.MINOR.PATCH , e.g. 1.2.3 . Release versions \u00b6 The version number for the first GA release starts from 1.0.0 and next release versions will be defined based on the nature of the delivered changes: If there is at least one backward-incompatible change, then the next version will be the next major version. If at least one functional change is delivered and all changes are backward-compatible, then the next release will be the next minor version. Any other backward-compatible bug fixes will be included in the next patch version. Breaking changes Any backward-incompatible changes to the infrastructure should bump the major version number.","title":"Versioning"},{"location":"userguide/VERSIONING/#versioning","text":"","title":"Versioning"},{"location":"userguide/VERSIONING/#release-naming","text":"Each product version is semantically versioned . Version names are defined by the following pattern: MAJOR.MINOR.PATCH , e.g. 1.2.3 .","title":"Release naming"},{"location":"userguide/VERSIONING/#release-versions","text":"The version number for the first GA release starts from 1.0.0 and next release versions will be defined based on the nature of the delivered changes: If there is at least one backward-incompatible change, then the next version will be the next major version. If at least one functional change is delivered and all changes are backward-compatible, then the next release will be the next minor version. Any other backward-compatible bug fixes will be included in the next patch version. Breaking changes Any backward-incompatible changes to the infrastructure should bump the major version number.","title":"Release versions"}]}